{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `yt`, `unyt` and `dask` ! \n",
    "\n",
    "In this notebook, we present an initial attempt at creating a `dask` Custom Collection for `unyt` arrays. As of `yt4.0`, the `yt.units` functionality [was extracted into the `unyt` package](https://yt-project.org/docs/dev/yt4differences.html?highlight=ytarray#yt-units-is-now-a-wrapper-for-unyt). The base [`unyt` arrays](https://unyt.readthedocs.io/en/stable/modules/unyt.array.html) are used throughout `yt` for tracking and converting units and so in order to fully leverage `dask` within `yt` it would be helpful to have `unyt` arrays with `dask` functionality. \n",
    "\n",
    "In general, `dask` builds task graphs to operate on `collections`. Some commonly used `collections` are `dask.array`, `dask.dataframe` and `dask.bag`. Each of these `collections` is subclassed off of the general `DaskMethodsMixin` collection and the dask documentation provides an overview of how to add [custom collections](https://docs.dask.org/en/latest/custom-collections.html#example-dask-collection). So what we want is a new collection, `unyt_dask_array`, that can be used for buliding and execulting dask task graphs in parallel while preseving `unyt_array` functionality. \n",
    "\n",
    "For the present problem, both `unyt` and `dask.array` wrap numpy methods and so the question is how do we cleverly wrap and sublcass to leverage the existing wrapped methods? The `dask` numpy wrappings account for the necessary distribution and reduction operations between chunks and so the simpler place to start is by subclassing `dask.array` and adding `unyt` functionality alongside. Tracking units does not have to happen on each chunk and so in the following, we track units and a cumulative unit conversion factor within our new `unyt_dask_array` class separately and only apply the final conversion when returning the result of a `dask.compute`. \n",
    "\n",
    "So let's just dump some code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unyt.array import unyt_array\n",
    "from dask.array.core import Array, finalize\n",
    "import numpy as np\n",
    "\n",
    "def unyt_from_dask(dask_array,\n",
    "                   units=None,\n",
    "                   registry=None,\n",
    "                   dtype=None,\n",
    "                   bypass_validation=False,\n",
    "                   input_units=None,\n",
    "                   name=None):\n",
    "    (cls, args) = dask_array.__reduce__()\n",
    "    da = unyt_dask_array(*args)\n",
    "    da._attach_units(units, registry, dtype, bypass_validation, input_units, name)\n",
    "    return da\n",
    "\n",
    "def finalize_unyt(results, unit_name, factor):\n",
    "    # the function to call for the __dask_postcompute__ hook.\n",
    "    return unyt_array(finalize(results) * factor, unit_name)\n",
    "\n",
    "def _attach_unyt(dask_array,unyt_da_instance):\n",
    "    # sets unyt data for a generated unyt_dask_array instance... would be better\n",
    "    # in unyt_dask_array.__new__ ... working out some conflicts with Array.__new__\n",
    "    # this works for now. \n",
    "    (cls, da_args) = dask_array.__reduce__()\n",
    "    out = unyt_dask_array(*da_args)\n",
    "    out.units = unyt_da_instance.units\n",
    "    out.unyt_name = unyt_da_instance.unyt_name\n",
    "    out.dask_name = unyt_da_instance.dask_name\n",
    "    out.factor = unyt_da_instance.factor\n",
    "    out._unyt_array = unyt_da_instance._unyt_array\n",
    "    return out\n",
    "\n",
    "class unyt_dask_array(Array):\n",
    "\n",
    "    def __init__(self, dask_graph, name, chunks, dtype=None, meta=None, shape=None):\n",
    "        self.units = None\n",
    "        self.unyt_name = None\n",
    "        self.dask_name = name\n",
    "        self.factor = 1.\n",
    "        self._unyt_array = None\n",
    "\n",
    "    def _attach_units(self, units=None,\n",
    "                      registry=None,\n",
    "                      dtype=None,\n",
    "                      bypass_validation=False,\n",
    "                      input_units=None,\n",
    "                      name=None):\n",
    "        x_np = np.array([1.])\n",
    "        self._unyt_array = unyt_array(x_np, units, registry, dtype, bypass_validation, input_units, name)\n",
    "        self.units = self._unyt_array.units\n",
    "        self.unyt_name = self._unyt_array.name\n",
    "\n",
    "    def to(self, units, equivalence=None, **kwargs):\n",
    "        # tracks any time units are converted with a running conversion factor\n",
    "        # that gets applied after calling dask methods\n",
    "        init_val = self._unyt_array.value[0]\n",
    "        self._unyt_array = self._unyt_array.to(units, equivalence, **kwargs)\n",
    "        self.factor = self.factor * self._unyt_array.value[0] / init_val\n",
    "        self.units = units\n",
    "        self.unyt_name = self._unyt_array.name\n",
    "\n",
    "    def min(self, axis=None, keepdims=False, split_every=None, out=None):\n",
    "        return _attach_unyt(super().min(axis, keepdims, split_every, out), self)\n",
    "\n",
    "    def max(self, axis=None, keepdims=False, split_every=None, out=None):\n",
    "        return _attach_unyt(super().max(axis, keepdims, split_every, out), self)\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        # unyt and dask implement this directly:\n",
    "        self._unyt_array = self._unyt_array.__pow__(other)\n",
    "        self.units = self._unyt_array.units\n",
    "        return _attach_unyt(super().__pow__(other), self)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        self.factor = self.factor * other.factor\n",
    "        self._unyt_array = self._unyt_array * other._unyt_array\n",
    "        self.units = self._unyt_array.units\n",
    "        return _attach_unyt(super().__mul__(other), self)\n",
    "\n",
    "    def __dask_postcompute__(self):\n",
    "        # a dask hook to catch after .compute(), see\n",
    "        # https://docs.dask.org/en/latest/custom-collections.html#example-dask-collection        \n",
    "        return finalize_unyt, ((self.units, self.factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we define four objects: the `unyt_from_dask` function, the `finalize_unyt` function, the `_attach_unyt` function  and the `unyt_dask_array` class. Let's focus on the new class first. \n",
    "\n",
    "In our new subclass, `unyt_dask_array(Array)`, `Array` is the core array class of `dask`. This class only has a `__new__` constructor, and so in the `__init__` here we only provide the arguments that get sent to `__new__`: \n",
    "\n",
    "\n",
    "```python\n",
    "def __init__(self, dask_graph, name, chunks, dtype=None, meta=None, shape=None):\n",
    "        self.units = None\n",
    "        self.unyt_name = None\n",
    "        self.dask_name = name\n",
    "        self.factor = 1.\n",
    "```\n",
    "\n",
    "all those arguments are those needed for the base `Array.__new__` constructor, and when we instantiate `unyt_dask_array` the super-class's `__new__` will be called with those arguments automatically before proceeding with `unyt_dask_array.__init__()`. \n",
    "\n",
    "These arguments are all related to the details of how dask constructs its graphs and chunks, but we want to be able to instantiate our `unyt_dask_array` more simply. Thus, the convenience function `unyt_from_dask` constructs our new `Array` subclass from an existing `dask` array without having to know the details of how `dask` works.\n",
    "\n",
    "So, for example, we can do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 800.00 MB </td> <td> 8.00 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (10000, 10000) </td> <td> (1000, 1000) </td></tr>\n",
       "    <tr><th> Count </th><td> 100 Tasks </td><td> 100 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"120\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"120\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"36\" x2=\"120\" y2=\"36\" />\n",
       "  <line x1=\"0\" y1=\"48\" x2=\"120\" y2=\"48\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"120\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"72\" x2=\"120\" y2=\"72\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"120\" y2=\"96\" />\n",
       "  <line x1=\"0\" y1=\"108\" x2=\"120\" y2=\"108\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"120\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"120\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"120\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"120\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"120\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"120\" />\n",
       "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"120\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"120\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">10000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(10000, 10000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import unyt; import dask.array as da\n",
    "\n",
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "x_da = unyt_from_dask(x, unyt.m)\n",
    "x_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which behaves as a `dask` array. e.g.,: \n",
    "\n",
    "For example, if we load everything into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array([[0.04576453, 0.87468941, 0.94322982, ..., 0.327398  ,\n",
       "             0.17318832, 0.81035252],\n",
       "            [0.66747439, 0.41645912, 0.60162428, ..., 0.6953135 ,\n",
       "             0.88182841, 0.43974718],\n",
       "            [0.69478361, 0.63520943, 0.73755502, ..., 0.53266357,\n",
       "             0.52167205, 0.1922259 ],\n",
       "            ...,\n",
       "            [0.58144625, 0.17870111, 0.7715346 , ..., 0.56317155,\n",
       "             0.65595637, 0.00497123],\n",
       "            [0.08852355, 0.433114  , 0.54194708, ..., 0.72537681,\n",
       "             0.13120661, 0.61182098],\n",
       "            [0.94835071, 0.63734746, 0.21300151, ..., 0.68246793,\n",
       "             0.01485714, 0.94517052]], 'm')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a `unyt_array`! This happens because of the `unyt_dask_array.__dask_postcompute__()` hook tells dask to call the `finalize_unyt` function after we execute `compute`. This function simply calls the `finalize` function used by the core dask `Array` and initializes a `unyt_array` with the resulting numpy array:\n",
    "\n",
    "```\n",
    "def finalize_unyt(results,unit_name,factor):\n",
    "    # the function to call for the __dask_postcompute__ hook. \n",
    "    return unyt_array(finalize(results)*factor,unit_name)\n",
    "```\n",
    "\n",
    "The `factor` is a cumulative unit conversion factor, [described below](#tracking-units).\n",
    "\n",
    "One caveat to the `__dask_postcompute__` hook is that it does not catch results from some of the methods. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 8 B </td> <td> 8 B </td></tr>\n",
       "    <tr><th> Shape </th><td> () </td> <td> () </td></tr>\n",
       "    <tr><th> Count </th><td> 239 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<sum-aggregate, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49994151.086279504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not catch and we just get a scalar factor. This is because the numpy array reductions implemented for the base `Array` class return a new `Array` instance, so when we do `x_da.sum()` the result is a base `Array` object that uses the base `Array.__dask_postcompute__` method. \n",
    "\n",
    "We do still have the units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but ideally we'd be returning a `unyt_array` or `unyt_quantity` here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to catch these operations, we can subclass appropriately... For example, the `unyt_dask_array` class has the following methods that call the corresponding superclass methods for `min` and `max` and then convert to a standard `ndarray` and then return a  `unyt_array`:\n",
    "\n",
    "```python\n",
    "    def min(self, axis=None, keepdims=False, split_every=None, out=None):\n",
    "        result = np.array(super().min(axis, keepdims, split_every, out))\n",
    "        return unyt_array(result*self.factor, self.units)\n",
    "\n",
    "    def max(self, axis=None, keepdims=False, split_every=None, out=None):\n",
    "        result = np.array(super().max(axis, keepdims, split_every, out))\n",
    "        return unyt_array(result*self.factor, self.units)\n",
    "```    \n",
    "\n",
    "So when we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array(3.02667147e-09, 'm')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.min().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get our standard `unyt_array`. \n",
    "\n",
    "We're currently working on a way to automate this with decorators so that we don't have to add a bunch of boiler plate code simply to attach units at the end -- there should be a way to catch the newly created `Array` objects and initialize new `unyt_dask_array` objects to return. Hopefully more on this soon...\n",
    "\n",
    "\n",
    "### tracking units \n",
    "\n",
    "We're also using a bit of trickery to deal with unit conversions in this class within the `unyt_dask_array.to` method, copied here:\n",
    "\n",
    "```python\n",
    "def to(self, units, equivalence=None, **kwargs):\n",
    "        # tracks any time units are converted with a running conversion factor\n",
    "        # that gets applied after calling dask methods\n",
    "        init_val = self._unyt_array.value[0]\n",
    "        self._unyt_array = self._unyt_array.to(units, equivalence, **kwargs)\n",
    "        self.factor = self.factor * self._unyt_array.value[0] / init_val\n",
    "        self.units = units\n",
    "        self.unyt_name = self._unyt_array.name\n",
    "```        \n",
    "\n",
    "so within our `unyt_dask_array`, we initialize a hidden `unyt_array` with a value of single value of `1`. Then any time a conversion occours, we apply the conversion to this `self._unyt_array` and track a cumulative conversion factor. Now, whenever we return calculations from `dask` into memory, we simply multiply by this conversion factor and attach the appropriate units. There is likely a more elegant solution here, but the basic idea is to track the units separately from the dask functionaly as the dask operations on each chunk are generally independent of the units scaling. \n",
    "\n",
    "So here's an example conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_da.to(unyt.km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "km"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array(3.02667147e-12, 'km')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_da.to(unyt.nanometer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array(3.02667147, 'nm')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.min().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from which we see our units changing appropriately. This approach is nice because when we convert multiple times: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_da.to(unyt.cm)\n",
    "x_da.to(unyt.micrometer)\n",
    "x_da.to(unyt.km)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are only operating on the hidden `_unyt_array` to track what the final conversion factor should be. In this case, we're converting back to our original units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array(3.02667147e-12, 'km')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.min().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above class, we also implemented a few methods for handling operations that combine arrays. For example, if we have a second `dask_unyt_array`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 800.00 MB </td> <td> 8.00 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (10000, 10000) </td> <td> (1000, 1000) </td></tr>\n",
       "    <tr><th> Count </th><td> 100 Tasks </td><td> 100 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"120\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"120\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"36\" x2=\"120\" y2=\"36\" />\n",
       "  <line x1=\"0\" y1=\"48\" x2=\"120\" y2=\"48\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"120\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"72\" x2=\"120\" y2=\"72\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"120\" y2=\"96\" />\n",
       "  <line x1=\"0\" y1=\"108\" x2=\"120\" y2=\"108\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"120\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"120\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"120\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"120\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"120\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"120\" />\n",
       "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"120\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"120\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">10000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(10000, 10000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_da = unyt_from_dask(da.random.random((10000, 10000), chunks=(1000, 1000)), unyt.s)\n",
    "x2_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then multiplying the two together results in the expected units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array([4.74724592e-09, 1.33501131e-08, 1.73077725e-08, ...,\n",
       "            2.21975535e-09, 6.91597564e-10, 2.07802170e-09], 'km*s')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x2_da * x_da).min(axis=0).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dask_unyt_array` class accomplishes this by catching calls to the element-wise multiplication and then multiplying the two hidden `_unyt_array` objects to determine the resulting units and then calling the normal dask `Array.__mul__` method: \n",
    "\n",
    "```python\n",
    "    def __mul__(self, other):\n",
    "        self.factor = self.factor * other.factor\n",
    "        self._unyt_array = self._unyt_array * other._unyt_array\n",
    "        self.units = self._unyt_array.units\n",
    "        return _attach_unyt(super().__mul__(other), self)\n",
    "```     \n",
    "\n",
    "The difficulty with this method is that we want to avoid manually subclassing the many methods in the base `Array` collection -- there is likely a clever way to automatically wrap all the methods (but so far it's proven difficult to slightly different applications of the numpy array protocols).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parallel!\n",
    "\n",
    "Now, because our `unyt_from_dask` class is built off of a `dask` collection, it will work with the parallel scheduling. \n",
    "\n",
    "So let's spin up a client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(threads_per_worker=2, n_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:33287</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>33.51 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:33287' processes=2 threads=4, memory=33.51 GB>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and re-instantiate our arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_da = unyt_from_dask(da.random.random((10000, 10000), chunks=(1000, 1000)), unyt.m)\n",
    "x_da2 = unyt_from_dask(da.random.random((10000, 10000), chunks=(1000, 1000)), unyt.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now when we compute our properties, `dask` will compute values from chunks independently. So when we take a min:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array(1.26752945e-08, 'm')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.min().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on our `dask` dashboard, we can see the distributed tasks complete via the Task Graph:\n",
    "\n",
    "\n",
    "![TaskStream](resources/unyt_dask_taskgraph.png)\n",
    "\n",
    "\n",
    "In the above example for `min` and `max`, we are converting the result from the superclass call to a standard `ndarray` as the results here will generally be small enough to be held in memory, even when returning an array using the `axis` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array([0.99987319, 0.9997248 , 0.99999173, ..., 0.99996989,\n",
       "            0.9999698 , 0.99989631], 'm')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.max(axis=0).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, when we convert units, we don't actually touch the dask array chunks but track a cumulative conversion factor using a hidden `_unyt_array` with a single value. So when we convert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_da.to(unyt.cm)\n",
    "x_da.to(unyt.micrometer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing gets distributed to the dask chunks. The conversion factor only gets applied to the chunks **after** the reduction step as part of the dask finalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array([999873.18619592, 999724.80425791, 999991.72966118, ...,\n",
       "            999969.89041921, 999969.80283928, 999896.30817156], 'μm')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_da.max(axis=0).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our array multiplication still works: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unyt_array(0.00052141, 'N**2*μm')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_da * x_da2).min().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in general, this method shows a fairly straightforward approach for adding dask support to `unyt` which can be in turn leveraged by `yt`. The main work to be done is to devise a more clever way to wrap the `dask.array` methods to attach the final units in order to avoid manually subclassing each method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
